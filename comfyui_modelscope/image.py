"""
ModelScopeå›¾åƒç”ŸæˆèŠ‚ç‚¹
"""

import os
import json
import time
import requests
import logging
import re
import uuid
from typing import List, Dict, Any, Tuple, Optional

try:
    import torch
    import numpy as np
    import comfy.utils
    import comfy.model_management
    from PIL import Image
    import io
    import base64
except ImportError:
    pass

from .config_loader import ConfigLoader
from .checkpoint import CheckpointNode
from .lora import LoraNode

class ModelScopeImageNode:
    """ModelScopeå›¾åƒç”ŸæˆèŠ‚ç‚¹"""
    
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "a photo of a beautiful woman"}),
                "width": ("INT", {"default": 928, "min": 256, "max": 2048, "step": 64}),
                "height": ("INT", {"default": 1664, "min": 256, "max": 2048, "step": 64}),
                "num_images": ("INT", {"default": 4, "min": 1, "max": 4, "step": 1}),
                "enable_hires": ("BOOLEAN", {"default": True}),
                "api_key": ("STRING", {"default": ""}),
                "cookie": ("STRING", {"multiline": True, "default": ""}),
            },
            "optional": {
                "checkpoint": ("CHECKPOINT",),
                "lora1": ("LORA",),
                "lora2": ("LORA",),
                "lora3": ("LORA",),
                "lora4": ("LORA",),
            }
        }
    
    RETURN_TYPES = ("STRING", "IMAGE", "STRING")
    RETURN_NAMES = ("image_urls", "images", "status_log")
    
    FUNCTION = "generate_images"
    
    def __init__(self):
        self.config_loader = ConfigLoader()
        
    def generate_images(self, prompt, width, height, num_images, enable_hires, api_key, cookie, 
                       checkpoint=None, lora1=None, lora2=None, lora3=None, lora4=None):
        """
        ç”Ÿæˆå›¾åƒ
        Args:
            prompt: æç¤ºè¯
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            num_images: ç”Ÿæˆå›¾åƒæ•°é‡
            enable_hires: æ˜¯å¦å¯ç”¨é«˜æ¸…ä¿®å¤
            api_key: APIå¯†é’¥
            cookie: ModelScope Cookie
            checkpoint: CheckpointèŠ‚ç‚¹
            lora1-4: LoRAèŠ‚ç‚¹
        Returns:
            tuple: (å›¾åƒURLåˆ—è¡¨, å›¾åƒå¼ é‡, çŠ¶æ€æ—¥å¿—)
        """
        # éªŒè¯å‚æ•°
        if not prompt:
            return ("", None, "é”™è¯¯: æç¤ºè¯ä¸èƒ½ä¸ºç©º")
            
        if width > 2048 or height > 2048:
            return ("", None, f"é”™è¯¯: å›¾åƒå°ºå¯¸ä¸èƒ½è¶…è¿‡2048x2048ï¼Œå½“å‰ä¸º{width}x{height}")
            
        # ä½¿ç”¨ä¼ å…¥çš„cookieæˆ–é…ç½®æ–‡ä»¶ä¸­çš„cookie
        model_scope_cookie = cookie if cookie else self.config_loader.get("model_scope_cookie", "")
        
        if not model_scope_cookie:
            return ("", None, "é”™è¯¯: æœªé…ç½®ModelScope Cookie")
            
        # æ„å»ºLoRAå‚æ•°
        lora_args = []
        for lora in [lora1, lora2, lora3, lora4]:
            if lora:
                lora_args.append(lora)
                
        # æ„å»ºcheckpointå‚æ•°
        checkpoint_args = {}
        if checkpoint:
            checkpoint_args = {
                "checkpointModelVersionId": checkpoint["modelVersionId"],
                "checkpointShowInfo": checkpoint["checkpointShowInfo"]
            }
        else:
            # ä½¿ç”¨é»˜è®¤checkpoint
            plugin_dir = os.path.dirname(os.path.realpath(__file__))
            checkpoint_file = os.path.join(plugin_dir, "checkpoint.json")
            checkpoints = ConfigLoader.load_json_file(checkpoint_file, [])
            if checkpoints:
                checkpoint_args = {
                    "checkpointModelVersionId": checkpoints[0]["checkpointModelVersionId"],
                    "checkpointShowInfo": checkpoints[0]["checkpointShowInfo"]
                }
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_data = {
            "taskType": "TXT_2_IMG",
            "predictType": "TXT_2_IMG",
            "modelArgs": {
                **checkpoint_args,
                "loraArgs": lora_args,
                "predictType": "TXT_2_IMG"
            },
            "promptArgs": {
                "prompt": f"feifei,a photo-realistic shoot from a portrait camera angle about a young woman,big boobs,å¦ƒå¦ƒ,{prompt}",
                "negativePrompt": ""
            },
            "basicDiffusionArgs": {
                "sampler": "Euler",
                "guidanceScale": 4,
                "seed": -1,
                "numInferenceSteps": 50,
                "numImagesPerPrompt": num_images,
                "width": width,
                "height": height
            },
            "advanced": False,
            "addWaterMark": False,
            "adetailerArgsMap": {},
            "hiresFixFrontArgs": {
                "modelName": "Nomos 8k SCHATL 4x",
                "scale": 4
            } if enable_hires else {},
            "controlNetFullArgs": []
        }
        
        # æå–CSRF Token
        csrf_token = self.extract_csrf_token(model_scope_cookie)
        if not csrf_token:
            logging.warning("[ModelScope] æ— æ³•ä»Cookieä¸­æå–CSRF Tokenï¼Œå¯èƒ½å½±å“è¯·æ±‚")
            
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Content-Type": "application/json",
            "Cookie": model_scope_cookie,
            "Origin": "https://www.modelscope.cn",
            "Referer": "https://www.modelscope.cn/aigc/imageGeneration",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
        }
        
        if csrf_token:
            headers["X-CSRF-TOKEN"] = csrf_token
            
        # å‘é€è¯·æ±‚
        api_url = "https://www.modelscope.cn/api/v1/muse/predict/task/submit"
        
        try:
            logging.info(f"[ModelScope] å¼€å§‹ç”Ÿæˆå›¾åƒï¼Œæç¤ºè¯: {prompt[:50]}{'...' if len(prompt) > 50 else ''}")
            logging.info(f"[ModelScope] å›¾åƒå°ºå¯¸: {width}x{height}, æ•°é‡: {num_images}, é«˜æ¸…ä¿®å¤: {enable_hires}")
            
            response = requests.post(api_url, json=request_data, headers=headers, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            
            if not result.get("Success"):
                error_msg = result.get("Message", "æœªçŸ¥é”™è¯¯")
                logging.error(f"[ModelScope] æäº¤ä»»åŠ¡å¤±è´¥: {error_msg}")
                return ("", None, f"æäº¤ä»»åŠ¡å¤±è´¥: {error_msg}")
                
            task_id = result["Data"]["taskId"]
            logging.info(f"[ModelScope] ä»»åŠ¡æäº¤æˆåŠŸï¼Œä»»åŠ¡ID: {task_id}")
            
            # è½®è¯¢ä»»åŠ¡çŠ¶æ€
            urls, status = self.poll_task_status(task_id, headers)
            
            if not urls:
                return ("", None, f"å›¾åƒç”Ÿæˆå¤±è´¥: {status}")
                
            # ä¸‹è½½å›¾åƒå¹¶è½¬æ¢ä¸ºComfyUIæ ¼å¼
            images = []
            image_urls = []
            
            for url in urls:
                try:
                    img_response = requests.get(url, timeout=30)
                    img_response.raise_for_status()
                    
                    # å°†å›¾åƒè½¬æ¢ä¸ºPILå¯¹è±¡
                    img = Image.open(io.BytesIO(img_response.content))
                    
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„
                    img_array = np.array(img).astype(np.float32) / 255.0
                    img_array = img_array[:, :, :3]  # ç¡®ä¿åªæœ‰RGBé€šé“
                    
                    # è½¬æ¢ä¸ºPyTorchå¼ é‡
                    img_tensor = torch.from_numpy(img_array)[None,]
                    images.append(img_tensor)
                    image_urls.append(url)
                    
                except Exception as e:
                    logging.error(f"[ModelScope] ä¸‹è½½æˆ–å¤„ç†å›¾åƒå¤±è´¥: {e}")
                    continue
                    
            if not images:
                return ("", None, "æ‰€æœ‰å›¾åƒä¸‹è½½æˆ–å¤„ç†å¤±è´¥")
                
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            combined_images = torch.cat(images, dim=0)
            
            log_message = f"æˆåŠŸç”Ÿæˆ{len(combined_images)}å¼ å›¾åƒï¼Œå°ºå¯¸: {width}x{height}"
            logging.info(f"[ModelScope] {log_message}")
            
            return ("\n".join(image_urls), combined_images, log_message)
            
        except requests.exceptions.RequestException as e:
            logging.error(f"[ModelScope] è¯·æ±‚å¤±è´¥: {e}")
            return ("", None, f"è¯·æ±‚å¤±è´¥: {e}")
        except Exception as e:
            logging.error(f"[ModelScope] ç”Ÿæˆå›¾åƒå¤±è´¥: {e}")
            return ("", None, f"ç”Ÿæˆå›¾åƒå¤±è´¥: {e}")
            
    def poll_task_status(self, task_id, headers, max_wait_time=300):
        """
        è½®è¯¢ä»»åŠ¡çŠ¶æ€
        Args:
            task_id: ä»»åŠ¡ID
            headers: è¯·æ±‚å¤´
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´(ç§’)
        Returns:
            tuple: (å›¾åƒURLåˆ—è¡¨, çŠ¶æ€æ¶ˆæ¯)
        """
        api_url = f"https://www.modelscope.cn/api/v1/muse/predict/task/status?taskId={task_id}"
        start_time = time.time()
        
        while time.time() - start_time < max_wait_time:
            try:
                response = requests.get(api_url, headers=headers, timeout=10)
                response.raise_for_status()
                
                result = response.json()
                
                if not result.get("Success"):
                    error_msg = result.get("Message", "æœªçŸ¥é”™è¯¯")
                    logging.error(f"[ModelScope] è½®è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {error_msg}")
                    return ([], f"è½®è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {error_msg}")
                    
                task_data = result["Data"]["data"]
                status = task_data.get("status", "")
                
                if status == "COMPLETED":
                    images = [item.get("url") for item in task_data.get("predictResult", []) if item and item.get("url")]
                    logging.info(f"[ModelScope] ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆäº†{len(images)}å¼ å›¾åƒ")
                    return (images, "ä»»åŠ¡å®Œæˆ")
                    
                elif status == "FAILED":
                    error_msg = task_data.get("errorMsg", "æœªçŸ¥é”™è¯¯")
                    logging.error(f"[ModelScope] ä»»åŠ¡å¤±è´¥: {error_msg}")
                    return ([], f"ä»»åŠ¡å¤±è´¥: {error_msg}")
                    
                elif status in ["PROCESSING", "QUEUING", "PENDING"]:
                    progress = task_data.get("progress", {})
                    percent = progress.get("percent", 0)
                    detail = progress.get("detail", "æ­£åœ¨å¤„ç†ä¸­...")
                    
                    logging.info(f"[ModelScope] ä»»åŠ¡çŠ¶æ€: {status}, è¿›åº¦: {percent}%, è¯¦æƒ…: {detail}")
                    
                else:
                    logging.warning(f"[ModelScope] æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {status}")
                    
                # ç­‰å¾…5ç§’åå†æ¬¡æŸ¥è¯¢
                time.sleep(5)
                
            except requests.exceptions.RequestException as e:
                logging.error(f"[ModelScope] è½®è¯¢è¯·æ±‚å¤±è´¥: {e}")
                time.sleep(5)
                
        return ([], "ä»»åŠ¡è¶…æ—¶")
        
    def extract_csrf_token(self, cookie_str):
        """
        ä»Cookieå­—ç¬¦ä¸²ä¸­æå–CSRF Token
        Args:
            cookie_str: Cookieå­—ç¬¦ä¸²
        Returns:
            str: CSRF Tokenï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            # æ¸…ç†cookieå­—ç¬¦ä¸²
            cookie_str = cookie_str.strip()
            
            # å°è¯•ä»csrf_tokenæ ¼å¼æå–
            match = re.search(r'csrf_token=([^;]+)', cookie_str)
            if match:
                token = match.group(1)
                # URLè§£ç 
                import urllib.parse
                token = urllib.parse.unquote(token)
                logging.debug(f"[ModelScope] ä»Cookieä¸­æå–CSRF Token: {token}")
                return token
                
        except Exception as e:
            logging.error(f"[ModelScope] æå–CSRF Tokenå¤±è´¥: {e}")
            
        return ""