"""
ModelScopeå›¾åƒç”ŸæˆèŠ‚ç‚¹
"""

import os
import time
import requests
import logging
import re

try:
    import torch
    import numpy as np
    from PIL import Image
    import io
except ImportError:
    torch = None
    numpy = None
    Image = None
    io = None

from .config_loader import ConfigLoader

class ModelScopeImageNode:
    """ModelScopeå›¾åƒç”ŸæˆèŠ‚ç‚¹"""
    
    CATEGORY = "ğŸ‡¨ğŸ‡³BOZO/PIC"
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "a photo of a beautiful woman"}),
                "width": ("INT", {"default": 928, "min": 256, "max": 2048, "step": 64}),
                "height": ("INT", {"default": 1664, "min": 256, "max": 2048, "step": 64}),
                "num_images": ("INT", {"default": 4, "min": 1, "max": 4, "step": 1}),
                "enable_hires": ("BOOLEAN", {"default": True}),
                
                "cookie": ("STRING", {"multiline": True, "default": ""}),
            },
            "optional": {
                "checkpoint": ("CHECKPOINT",),
                "lora1": ("LORA",),
                "lora2": ("LORA",),
                "lora3": ("LORA",),
                "lora4": ("LORA",),
            }
        }
    
    RETURN_TYPES = ("STRING", "IMAGE", "STRING")
    RETURN_NAMES = ("image_urls", "images", "status_log")
    
    FUNCTION = "generate_images"
    
    def __init__(self):
        self.config_loader = ConfigLoader()
        
    def generate_images(self, prompt, width, height, num_images, enable_hires, cookie, 
                       checkpoint=None, lora1=None, lora2=None, lora3=None, lora4=None):
        """
        ç”Ÿæˆå›¾åƒ
        Args:
            prompt: æç¤ºè¯
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            num_images: ç”Ÿæˆå›¾åƒæ•°é‡
            enable_hires: æ˜¯å¦å¯ç”¨é«˜æ¸…ä¿®å¤
            cookie: ModelScope Cookie
            checkpoint: CheckpointèŠ‚ç‚¹
            lora1-4: LoRAèŠ‚ç‚¹
        Returns:
            tuple: (å›¾åƒURLåˆ—è¡¨, å›¾åƒå¼ é‡, çŠ¶æ€æ—¥å¿—)
        """
        # éªŒè¯å‚æ•°
        if not prompt:
            empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32) if torch else None
            return ("", empty_tensor, "é”™è¯¯: æç¤ºè¯ä¸èƒ½ä¸ºç©º")
            
        if width > 2048 or height > 2048:
            empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32) if torch else None
            return ("", empty_tensor, f"é”™è¯¯: å›¾åƒå°ºå¯¸ä¸èƒ½è¶…è¿‡2048x2048ï¼Œå½“å‰ä¸º{width}x{height}")
            
        # ä½¿ç”¨ä¼ å…¥çš„cookieæˆ–é…ç½®æ–‡ä»¶ä¸­çš„cookie
        model_scope_cookie = cookie if cookie else self.config_loader.get("model_scope_cookie", "")
        
        if not model_scope_cookie:
            empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32) if torch else None
            return ("", empty_tensor, "é”™è¯¯: æœªé…ç½®ModelScope Cookie")
            
        # æ„å»ºLoRAå‚æ•°
        lora_args = []
        for lora in [lora1, lora2, lora3, lora4]:
            if lora:
                lora_args.append(lora)
                
        # æ„å»ºcheckpointå‚æ•°
        checkpoint_args = {}
        if checkpoint:
            checkpoint_args = {
                "checkpointModelVersionId": checkpoint["modelVersionId"],
                "checkpointShowInfo": checkpoint["checkpointShowInfo"]
            }
        else:
            # ä½¿ç”¨é»˜è®¤checkpoint
            plugin_dir = os.path.dirname(os.path.realpath(__file__))
            checkpoint_file = os.path.join(plugin_dir, "checkpoint.json")
            checkpoints = ConfigLoader.load_json_file(checkpoint_file, [])
            if checkpoints:
                checkpoint_args = {
                    "checkpointModelVersionId": checkpoints[0]["checkpointModelVersionId"],
                    "checkpointShowInfo": checkpoints[0]["checkpointShowInfo"]
                }
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_data = {
            "taskType": "TXT_2_IMG",
            "predictType": "TXT_2_IMG",
            "modelArgs": {
                **checkpoint_args,
                "loraArgs": lora_args,
                "predictType": "TXT_2_IMG"
            },
            "promptArgs": {
                "prompt": f"feifei,a photo-realistic shoot from a portrait camera angle about a young woman,big boobs,å¦ƒå¦ƒ,{prompt}",
                "negativePrompt": ""
            },
            "basicDiffusionArgs": {
                "sampler": "Euler",
                "guidanceScale": 4,
                "seed": -1,
                "numInferenceSteps": 50,
                "numImagesPerPrompt": num_images,
                "width": width,
                "height": height
            },
            "advanced": False,
            "addWaterMark": False,
            "adetailerArgsMap": {},
            "hiresFixFrontArgs": {
                "modelName": "Nomos 8k SCHATL 4x",
                "scale": 4
            } if enable_hires else {},
            "controlNetFullArgs": []
        }
        
        # æå–CSRF Token
        csrf_token = self.extract_csrf_token(model_scope_cookie)
        if not csrf_token:
            logging.warning("[ModelScope] æ— æ³•ä»Cookieä¸­æå–CSRF Tokenï¼Œå¯èƒ½å½±å“è¯·æ±‚")
            
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Content-Type": "application/json",
            "Cookie": model_scope_cookie,
            "Origin": "https://www.modelscope.cn",
            "Referer": "https://www.modelscope.cn/aigc/imageGeneration",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
        }
        
        if csrf_token:
            headers["X-CSRF-TOKEN"] = csrf_token
            
        # å‘é€è¯·æ±‚
        api_url = "https://www.modelscope.cn/api/v1/muse/predict/task/submit"
        
        try:
            logging.info(f"[ModelScope] å¼€å§‹ç”Ÿæˆå›¾åƒï¼Œæç¤ºè¯: {prompt[:50]}{'...' if len(prompt) > 50 else ''}")
            logging.info(f"[ModelScope] å›¾åƒå°ºå¯¸: {width}x{height}, æ•°é‡: {num_images}, é«˜æ¸…ä¿®å¤: {enable_hires}")
            
            response = requests.post(api_url, json=request_data, headers=headers, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            
            # æ‰“å°å®Œæ•´å“åº”ä»¥ä¾¿è°ƒè¯•
            logging.info(f"[ModelScope] APIå“åº”: {result}")
            
            if not result.get("Success"):
                error_msg = result.get("Message", "æœªçŸ¥é”™è¯¯")
                logging.error(f"[ModelScope] æäº¤ä»»åŠ¡å¤±è´¥: {error_msg}")
                return ("", None, f"æäº¤ä»»åŠ¡å¤±è´¥: {error_msg}")
                
            # æ£€æŸ¥å“åº”æ•°æ®ç»“æ„
            if "Data" not in result:
                logging.error(f"[ModelScope] APIå“åº”æ ¼å¼ä¸æ­£ç¡®: {result}")
                empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32) if torch else None
                return ("", empty_tensor, "APIå“åº”æ ¼å¼ä¸æ­£ç¡®")
                
            # æ£€æŸ¥taskIdä½ç½®
            task_id = None
            if "taskId" in result["Data"]:
                task_id = result["Data"]["taskId"]
            elif "data" in result["Data"] and "taskId" in result["Data"]["data"]:
                task_id = result["Data"]["data"]["taskId"]
            else:
                logging.error(f"[ModelScope] æ— æ³•ä»APIå“åº”ä¸­è·å–taskId: {result}")
                empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32) if torch else None
                return ("", empty_tensor, "æ— æ³•ä»APIå“åº”ä¸­è·å–taskId")
                
            logging.info(f"[ModelScope] ä»»åŠ¡æäº¤æˆåŠŸï¼Œä»»åŠ¡ID: {task_id}")
            
            # è½®è¯¢ä»»åŠ¡çŠ¶æ€ï¼Œå…ˆç­‰å¾…å‡ ç§’è®©ä»»åŠ¡å¼€å§‹å¤„ç†
            logging.info("[ModelScope] ç­‰å¾…ä»»åŠ¡å¼€å§‹å¤„ç†...")
            time.sleep(5)  # åˆå§‹ç­‰å¾…5ç§’
            urls, status = self.poll_task_status(task_id, headers)
            
            if not urls:
                # åˆ›å»ºä¸€ä¸ªç©ºçš„å¼ é‡ï¼Œé¿å…ComfyUIæŠ¥é”™
                empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32)
                return ("", empty_tensor, f"å›¾åƒç”Ÿæˆå¤±è´¥: {status}")
                
            # ä¸‹è½½å›¾åƒå¹¶è½¬æ¢ä¸ºComfyUIæ ¼å¼
            images = []
            image_urls = []
            
            for url in urls:
                try:
                    img_response = requests.get(url, timeout=30)
                    img_response.raise_for_status()
                    
                    # å°†å›¾åƒè½¬æ¢ä¸ºPILå¯¹è±¡
                    img = Image.open(io.BytesIO(img_response.content))
                    
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„
                    img_array = np.array(img).astype(np.float32) / 255.0
                    img_array = img_array[:, :, :3]  # ç¡®ä¿åªæœ‰RGBé€šé“
                    
                    # è½¬æ¢ä¸ºPyTorchå¼ é‡
                    img_tensor = torch.from_numpy(img_array)[None,]
                    images.append(img_tensor)
                    image_urls.append(url)
                    
                except Exception as e:
                    logging.error(f"[ModelScope] ä¸‹è½½æˆ–å¤„ç†å›¾åƒå¤±è´¥: {e}")
                    continue
                    
            if not images:
                # åˆ›å»ºä¸€ä¸ªç©ºçš„å¼ é‡ï¼Œé¿å…ComfyUIæŠ¥é”™
                empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32) if torch else None
                return ("", empty_tensor, "æ‰€æœ‰å›¾åƒä¸‹è½½æˆ–å¤„ç†å¤±è´¥")
                
            # åˆå¹¶æ‰€æœ‰å›¾åƒ
            combined_images = torch.cat(images, dim=0)
            
            log_message = f"æˆåŠŸç”Ÿæˆ{len(combined_images)}å¼ å›¾åƒï¼Œå°ºå¯¸: {width}x{height}"
            logging.info(f"[ModelScope] {log_message}")
            
            return ("\n".join(image_urls), combined_images, log_message)
            
        except requests.exceptions.RequestException as e:
            logging.error(f"[ModelScope] è¯·æ±‚å¤±è´¥: {e}")
            # åˆ›å»ºä¸€ä¸ªç©ºçš„å¼ é‡ï¼Œé¿å…ComfyUIæŠ¥é”™
            empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32) if torch else None
            return ("", empty_tensor, f"è¯·æ±‚å¤±è´¥: {e}")
        except Exception as e:
            logging.error(f"[ModelScope] ç”Ÿæˆå›¾åƒå¤±è´¥: {e}")
            # åˆ›å»ºä¸€ä¸ªç©ºçš„å¼ é‡ï¼Œé¿å…ComfyUIæŠ¥é”™
            empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32) if torch else None
            return ("", empty_tensor, f"ç”Ÿæˆå›¾åƒå¤±è´¥: {e}")
            
    def poll_task_status(self, task_id, headers, max_wait_time=600):
        """
        è½®è¯¢ä»»åŠ¡çŠ¶æ€
        Args:
            task_id: ä»»åŠ¡ID
            headers: è¯·æ±‚å¤´
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´(ç§’)
        Returns:
            tuple: (å›¾åƒURLåˆ—è¡¨, çŠ¶æ€æ¶ˆæ¯)
        """
        api_url = f"https://www.modelscope.cn/api/v1/muse/predict/task/status?taskId={task_id}"
        start_time = time.time()
        
        while time.time() - start_time < max_wait_time:
            try:
                response = requests.get(api_url, headers=headers, timeout=10)
                response.raise_for_status()
                
                result = response.json()
                
                # æ‰“å°å®Œæ•´å“åº”ä»¥ä¾¿è°ƒè¯•
                logging.debug(f"[ModelScope] è½®è¯¢APIå“åº”: {result}")
                
                if not result.get("Success"):
                    error_msg = result.get("Message", "æœªçŸ¥é”™è¯¯")
                    logging.error(f"[ModelScope] è½®è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {error_msg}")
                    return ([], f"è½®è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {error_msg}")
                    
                # æ£€æŸ¥å“åº”æ•°æ®ç»“æ„
                if "Data" not in result:
                    logging.error(f"[ModelScope] è½®è¯¢APIå“åº”æ ¼å¼ä¸æ­£ç¡®: {result}")
                    return ([], "è½®è¯¢APIå“åº”æ ¼å¼ä¸æ­£ç¡®")
                    
                # æ£€æŸ¥dataä½ç½®
                task_data = None
                if "data" in result["Data"]:
                    task_data = result["Data"]["data"]
                else:
                    # å¯èƒ½æ˜¯ç›´æ¥åœ¨Dataä¸­
                    task_data = result["Data"]
                    
                if not task_data:
                    logging.error(f"[ModelScope] æ— æ³•ä»è½®è¯¢APIå“åº”ä¸­è·å–ä»»åŠ¡æ•°æ®: {result}")
                    return ([], "æ— æ³•ä»è½®è¯¢APIå“åº”ä¸­è·å–ä»»åŠ¡æ•°æ®")
                status = task_data.get("status", "")
                
                if status == "COMPLETED" or status == "SUCCEED":
                    # å°è¯•ä»ä¸åŒä½ç½®è·å–å›¾åƒ
                    images = []
                    
                    # å°è¯•ä»predictResult.imagesè·å–
                    if "predictResult" in task_data and isinstance(task_data["predictResult"], dict):
                        predict_result = task_data["predictResult"]
                        if "images" in predict_result and isinstance(predict_result["images"], list):
                            # ä»æ¯ä¸ªå›¾åƒå¯¹è±¡ä¸­æå–imageUrlå­—æ®µ
                            for img_obj in predict_result["images"]:
                                if isinstance(img_obj, dict) and "imageUrl" in img_obj:
                                    images.append(img_obj["imageUrl"])
                    
                    # å°è¯•ä»predictResultè·å–ï¼ˆæ—§æ ¼å¼ï¼‰
                    elif "predictResult" in task_data and isinstance(task_data["predictResult"], list):
                        images = [item.get("url") for item in task_data.get("predictResult", []) if item and isinstance(item, dict) and item.get("url")]
                    
                    # å°è¯•ä»imagesè·å–
                    elif "images" in task_data and isinstance(task_data["images"], list):
                        for img_obj in task_data["images"]:
                            if isinstance(img_obj, dict) and "imageUrl" in img_obj:
                                images.append(img_obj["imageUrl"])
                            elif isinstance(img_obj, str):
                                images.append(img_obj)
                            elif isinstance(img_obj, dict) and "url" in img_obj:
                                images.append(img_obj["url"])
                    
                    # å°è¯•ä»resultä¸­è·å–
                    elif "result" in task_data and isinstance(task_data["result"], dict):
                        result_data = task_data["result"]
                        if "images" in result_data and isinstance(result_data["images"], list):
                            for img_obj in result_data["images"]:
                                if isinstance(img_obj, dict) and "imageUrl" in img_obj:
                                    images.append(img_obj["imageUrl"])
                                elif isinstance(img_obj, str):
                                    images.append(img_obj)
                                elif isinstance(img_obj, dict) and "url" in img_obj:
                                    images.append(img_obj["url"])
                        elif "image_urls" in result_data:
                            images = result_data.get("image_urls", [])
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                    logging.info(f"[ModelScope] ä»»åŠ¡å®Œæˆï¼ŒçŠ¶æ€: {status}ï¼Œç”Ÿæˆäº†{len(images)}å¼ å›¾åƒ")
                    if not images:
                        logging.warning(f"[ModelScope] æ— æ³•ä»å“åº”ä¸­æå–å›¾åƒURLï¼Œä»»åŠ¡æ•°æ®: {task_data}")
                    else:
                        logging.info(f"[ModelScope] æˆåŠŸæå–å›¾åƒURL: {images}")
                    
                    return (images, f"ä»»åŠ¡å®Œæˆ({status})")
                    
                elif status == "FAILED":
                    error_msg = task_data.get("errorMsg", "æœªçŸ¥é”™è¯¯")
                    logging.error(f"[ModelScope] ä»»åŠ¡å¤±è´¥: {error_msg}")
                    return ([], f"ä»»åŠ¡å¤±è´¥: {error_msg}")
                    
                elif status in ["PROCESSING", "QUEUING", "PENDING"]:
                    progress = task_data.get("progress", {})
                    percent = progress.get("percent", 0)
                    detail = progress.get("detail", "æ­£åœ¨å¤„ç†ä¸­...")
                    
                    logging.info(f"[ModelScope] ä»»åŠ¡çŠ¶æ€: {status}, è¿›åº¦: {percent}%, è¯¦æƒ…: {detail}")
                    
                    # æ™ºèƒ½è½®è¯¢é—´éš”ï¼šæ’é˜Ÿæ—¶ä½¿ç”¨è¾ƒé•¿é—´éš”ï¼Œå¤„ç†æ—¶ä½¿ç”¨è¾ƒçŸ­é—´éš”
                    if status == "QUEUING" or "æ’é˜Ÿ" in detail:
                        # æ’é˜Ÿæ—¶ï¼Œé—´éš”15ç§’
                        time.sleep(15)
                    elif status == "PROCESSING":
                        # å¤„ç†ä¸­ï¼Œé—´éš”8ç§’
                        time.sleep(8)
                    else:
                        # å…¶ä»–çŠ¶æ€ï¼Œé—´éš”10ç§’
                        time.sleep(10)
                        
                else:
                    logging.warning(f"[ModelScope] æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {status}")
                    # æœªçŸ¥çŠ¶æ€ï¼Œä½¿ç”¨æ ‡å‡†é—´éš”
                    time.sleep(10)
                
            except requests.exceptions.RequestException as e:
                logging.error(f"[ModelScope] è½®è¯¢è¯·æ±‚å¤±è´¥: {e}")
                time.sleep(10)
                
        # å¦‚æœè¶…æ—¶ï¼Œè¿”å›ç©ºå›¾åƒåˆ—è¡¨
        logging.warning(f"[ModelScope] ä»»åŠ¡è½®è¯¢è¶…æ—¶ï¼Œå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´")
        return ([], "ä»»åŠ¡è¶…æ—¶")
        
    def extract_csrf_token(self, cookie_str):
        """
        ä»Cookieå­—ç¬¦ä¸²ä¸­æå–CSRF Token
        Args:
            cookie_str: Cookieå­—ç¬¦ä¸²
        Returns:
            str: CSRF Tokenï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        try:
            # æ¸…ç†cookieå­—ç¬¦ä¸²
            cookie_str = cookie_str.strip()
            
            # å°è¯•ä»csrf_tokenæ ¼å¼æå–
            match = re.search(r'csrf_token=([^;]+)', cookie_str)
            if match:
                token = match.group(1)
                # URLè§£ç 
                import urllib.parse
                token = urllib.parse.unquote(token)
                logging.debug(f"[ModelScope] ä»Cookieä¸­æå–CSRF Token: {token}")
                return token
                
        except Exception as e:
            logging.error(f"[ModelScope] æå–CSRF Tokenå¤±è´¥: {e}")
            
        return ""